FreeSwim: Revisiting Sliding-Window Attention Mechanisms for Training-Free Ultra-High-Resolution Video Generation ğŸ¥âœ¨

Introduction ğŸš€

FreeSwim introduces a novel training-free approach for generating ultra-high-resolution videos, tackling the high computational cost of training large video models. Our method leverages pre-trained Diffusion Transformers (DiTs) at lower resolutions and synthesizes high-resolution videos efficiently without additional training. At the heart of FreeSwim is a unique sliding-window attention mechanism that preserves fine-grained visual details and high fidelity, addressing the inherent issues of repetitive patterns and lack of global coherence in video generation. This paper presents an innovative dual-path pipeline with a cross-attention override strategy, ensuring both local details and semantic consistency are maintained in high-resolution video generation.

ğŸŒŸ Key Highlights:

Training-Free: Generate high-quality, high-resolution videos without additional model training.

Efficient: Achieves 2x speedup with cross-attention caching.

High-Resolution: Synthesize 4K resolution videos with fine-grained details.

Key Contributions ğŸ¯

Training-Free Ultra-High-Resolution Video Generation: ğŸ¥ We introduce FreeSwim, a method that utilizes pre-trained DiTs to generate videos at high resolutions without the need for further training or model adaptation.

Inward Sliding-Window Attention: ğŸ” A critical component that maintains a local receptive field size during inference, improving detail preservation and reducing artifacts.

Dual-Path Architecture: ğŸ”„ Combines local window attention with a full-attention branch to ensure semantic accuracy and avoid content repetition.

Efficiency Improvements: âš¡ Implements a cross-attention caching strategy, significantly speeding up inference without sacrificing video quality, achieving over 2x speedup.

Methodology ğŸ§ 

Coarse-to-Fine Generation: ğŸ–¥ï¸ The initial video is generated at the modelâ€™s native resolution and refined through a high-resolution upsampling process.

Inward Sliding-Window Attention: ğŸ”„ Ensures that the receptive field during inference matches the training resolution, maintaining local coherence.

Cross-Attention Override: ğŸŒ A dual-path mechanism where the full-attention branch provides global semantic guidance to the window attention branch, ensuring high-quality output without repetitive patterns.

Feature Reuse Strategy: ğŸ”„ Reduces computational costs by reusing cross-attention features from the full-attention branch during inference, enabling high-resolution generation with minimal performance loss.

Results ğŸ†

FreeSwim outperforms previous state-of-the-art methods in both video quality and efficiency across multiple benchmarks, including VBench, with significant improvements in aesthetic appeal, imaging quality, and overall consistency. It provides a training-free solution for generating 4K resolution videos, achieving fine-grained details and semantic consistency. ğŸŒˆ

Installation ğŸ› ï¸

To install the required dependencies:

Install Diffusers v4.46.2:

pip install diffusers==4.46.2


Set up the model and dataset paths as specified in the configuration file.

Usage ğŸ“ˆ

To run inference with FreeSwim, you need to specify the following command-line arguments:

python generate_video.py --mode cache --target_height 1080 --target_width 1920

Command Line Arguments: ğŸ–¥ï¸

--mode: Specify either cache or nocache mode.


--target_height: The target height for resizing the generated video.


--target_width: The target width for resizing the generated video.


Example: ğŸ¬
python generate_video.py --mode cache --target_height 1080 --target_width 1920


This command will run inference in cache mode and generate a video resized to 1080p by 1920p. ğŸŒŸ

Future Work ğŸ”®

Scaling for even higher resolutions: ğŸŒŸ Investigate the possibility of generating 8K videos with enhanced local and global consistency.

Enhanced Caching Strategies: âš¡ Further optimize the cross-attention caching process to improve speed for extremely high-resolution video generation.

License ğŸ“œ

This project is licensed under the MIT License - see the LICENSE
 file for details.
